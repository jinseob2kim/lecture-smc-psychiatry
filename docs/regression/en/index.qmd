---
title: "Regression Analysis in <br><b>Medical Research</b>"
author: 
  name: Jinseob Kim
  url: https://github.com/jinseob2kim
institute: Zarathu
format:
  revealjs:
    scrollable: true
    css: ["css/footer-header.css"]
    slide-number: true
    progress: true
    ratio: 4:3
    highlight-style: github
    code-line-numbers: true
    code-overflow: wrap
    self-contained: false
    include-before-body: js/macros.js
editor:
  render-on-save: true
execute:
  echo: true
  output: console
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = T, fig.align = "center", message = F, warning = F)
library(knitr);library(DT);library(survival);library(jstable);library(jskm);library(survsim);library(here);library(readxl); library(writexl)
colon <- na.omit(colon)
```

# Executive Summary 

|                      | Default           | Repeated Measure | Survey     |
|----------------------|-------------------|------------------|------------|
| **Continuous**       | Linear regression | GEE              | Survey GLM |
| **Event**            | GLM (logistic)    | GEE              | Survey GLM |
| **Time & Event**     | Cox               | Marginal Cox     | Survey Cox |
| **0,1,2,3 (rare event)** | GLM (Poisson)     | GEE              | Survey GLM |

# Practice Dataset

```{r, echo = FALSE, out.width='65%'}
colon <- read_excel(here("data", "colon.xlsx"))
datatable(colon, rownames = FALSE)
```

# Linear regression
**Continuous**

# Simple 

```{r, echo=FALSE, fig.align='center', out.width='85%'}
knitr::include_graphics(here("images", "linear-regression.png"))
```

$$Y = \beta_0 + \beta_1 X + \epsilon$$
**Estimate $\beta_0$, $\beta_1$ by minimizing sum of squared errors**

- $Y$ must be continuous & normally distributed

- $X$ can be continuous or categorical

    + If continuous: same as correlation analysis

    + If binary: same as t-test with equal variance

## Bivariate Correlation

Use the **Bivariate Correlation** function to test linear association between two continuous variables.

- **Analyze → Correlate → Bivariate…**
```{r, echo=FALSE, out.width='50%'}
knitr::include_graphics(here("images", "cor1.png"))
```

- Move **age** and **nodes** into the **Variables** box  
- Select **Pearson** as the correlation coefficient  
- Choose **Two-tailed** test of significance
```{r, echo=FALSE, out.width='50%'}
knitr::include_graphics(here("images", "cor2.png"))
```

```{r, echo=FALSE, out.width='40%'}
knitr::include_graphics(here("images", "cor3.png"))
```
- **Pearson correlation**: r = -0.093  
- **p-value**: < .001 → statistically significant  
- **Sample size**: N = 1822

There is a **weak negative**, yet statistically significant, correlation between **age** and **nodes**.

## Linear Regression: Predicting Nodes from Age

This regression estimates how **age** affects **nodes** (number of affected lymph nodes).

Go to **Analyze → Regression → Linear…**  
```{r, echo=FALSE, out.width='50%'}
knitr::include_graphics(here("images", "lr1.png"))
```

Set **nodes** as the **Dependent** variable and **age** as the **Independent(s)** variable.
```{r, echo=FALSE, out.width='50%'}
knitr::include_graphics(here("images", "lr2.png"))
```

```{r, echo=FALSE, out.width='70%'}
knitr::include_graphics(here("images", "lr3.png"))
```
- **R = .093**, **R² = .009**: Very weak linear relationship

- **Unstandardized coefficient for age = -0.028**, **p < .001**

As age increases by 1 year, the number of nodes is expected to decrease by 0.028. The relationship is statistically significant but weak.

## Linear Regression: Predicting Age from Nodes

This reverses the regression direction, predicting **age** from **nodes**.

Go to **Analyze → Regression → Linear…**  
Set **age** as the **Dependent** variable and **nodes** as the **Independent(s)** variable.

```{r, echo=FALSE, out.width='80%'}
knitr::include_graphics(here("images", "lr4(nodes).png"))
```
- **R = .093**, **R² = .009**: Same strength as the previous model (symmetric)  
- **Unstandardized coefficient for nodes = -0.309**, **p < .001**

Although both models are statistically significant (p < .001), the effect size (R² ≈ 0.009) is very small. This indicates that **only about 0.9% of the variance** in either variable is explained by the other.

# T-tests & Simple Linear Regression 
**are equivalent when comparing 2 groups**

## Independent Samples T-test: Comparing Time by Sex

To compare the variable **time** between male and female groups using a t-test in SPSS:

```{r, echo=FALSE, out.width='70%'}
knitr::include_graphics(here("images", "tt.png"))
```

- **t = -0.317**, **df = 1856**, **p = 0.751**  
- No statistically significant difference in mean **time** between groups  

We begin with a t-test because it is a simple, standard method for comparing group means when the predictor has only two levels. It provides the same result as regression but is more intuitive in this context.

## Simple Linear Regression: Predicting Time from Sex

This analysis fits a linear regression model where **time** is predicted by **sex**.

```{r, echo=FALSE, out.width='50%'}
knitr::include_graphics(here("images", "lrt1.png"))
```

Go to **Analyze → Regression → Linear…**  
Set **time** as the **Dependent** variable and **sex** as the **Independent(s)** variable.

```{r, echo=FALSE, out.width='50%'}
knitr::include_graphics(here("images", "lrt2.png"))
```

```{r, echo=FALSE, out.width='50%'}
knitr::include_graphics(here("images", "lrt3.png"))
```
The regression result is consistent with the t-test:

> There is **no statistically significant association** between sex and time.  

# More than 2 Groups?

## Changing string into numeric in SPSS
The variable `rx` includes **three treatment groups**:  
- `1 = Lev`  
- `2 = Lev+5FU`
- `3 = Obs` (reference)  
```{r, echo=FALSE, out.width='50%'}
knitr::include_graphics(
  normalizePath(here::here("images", c("rrx1.png", "rrx2.png")))
)
```
In SPSS, linear regression **does not automatically treat string variables as categorical**.
To include a categorical variable like `rx` in a regression model, we must first convert it to numeric.

Use **Automatic Recode** if your original `rx` is a string variable. This assigns numeric values starting from 1: `1 = Lev, 2 = Lev+5FU, 3 = Obs`

> If it is a numeric variable, SPSS automatically chooses the lowest numeric value as the **reference category**.

```{r, echo=FALSE, out.width='80%'}
knitr::include_graphics(here("images", "rx.png"))
```
This will assign numeric values starting from 1.

> Now that `rx_new` is numeric, SPSS will automatically create dummy variables when used in regression BUT it will use the lowest number as the reference group (e.g., 1 = Lev). To change the reference group (e.g., set 3 = Obs), go to **Categorical...** and select it manually.

## Linear Regression with Categorical Variables (3 Groups)

Go to **Transform → Compute Variable…**
To include a 3-group variable in regression, create two dummy variables:  
- `rx_lev` = 1 if `rx_new == 1`, else 0  
- `rx_lev5fu` = 1 if `rx_new == 2`, else 0
```{r, echo=FALSE, out.width='85%'}
knitr::include_graphics(here("images", "rx3.png"))
```

```{r, echo=FALSE, out.width='85%'}
knitr::include_graphics(here("images", "rx4.png"))
```
The reference group **(row where all dummy variables are 0)** is **Obs**, which is not coded explicitly.

Use **Analyze → Regression → Linear**  
```{r, echo=FALSE, out.width='85%'}
knitr::include_graphics(here("images", "rx2.png"))
```
- Dependent variable: `time`  
- Independent variables: `rx_lev`, `rx_lev5fu`
```{r, echo=FALSE, out.width='85%'}
knitr::include_graphics(here("images", "rx5.png"))
```

The constant is the mean for the **Obs group**. Coefficients show the difference from Obs:
- `rx_lev` = difference between **Lev** and **Obs**  
- `rx_lev5fu` = difference between **Lev+5FU** and **Obs**
```{r, echo=FALSE, out.width='85%'}
knitr::include_graphics(here("images", "rx6.png"))
```
Only `rx_lev5fu` shows a significant difference (p < .001)

## Alternative: One-Way ANOVA
Use **Analyze → Compare Means → One-Way ANOVA**  
to test whether any of the `rx_new` groups differ overall.
- Dependent = `time`  
- Factor = `rx_new`  
```{r, echo=FALSE, out.width='85%'}
knitr::include_graphics(here("images", "ano1.png"))
```
- Options → Check **Homogeneity of variance test** (Levene’s test)  
```{r, echo=FALSE, out.width='40%'}
knitr::include_graphics(here("images", "ano2.png"))
```
This gives an overall p-value for overall group comparison.
```{r, echo=FALSE, out.width='85%'}
knitr::include_graphics(here("images", "ano3.png"))
```

# Multiple Variables

## Including multiple variables

$$Y = \beta_0 + \beta_1 X_{1} + \beta_2 X_{2} + \cdots + \epsilon$$

- Interpretation of $\beta_1$: When adjusting for $X_2$, $X_3$, etc., a one-unit increase in $X_1$ leads to an increase of $\beta_1$ in $Y$.

```{r, echo=FALSE, out.width='60%'}
knitr::include_graphics(here("images", "multiple1.png"))
```
```{r, echo=FALSE, out.width='70%'}
knitr::include_graphics(here("images", "multiple2.png"))
```

## In academic papers,
**it is common to present results both before and after adjustment**.


**Unadjusted**
Analyze each variable one at a time:
- Go to **Analyze → Regression → Linear**
- Set `time` as **Dependent**
- Add one predictor (e.g., `sex`) to **Independent(s)**

**Adjusted**
Control for multiple variables:
- Set `time` as **Dependent**
- Add all predictors (e.g., `sex`, `age`, `rx`) to **Independent(s)**

This allows comparison of crude vs. adjusted effects.

# Logistic regression

**Used for Binary Outcomes: 0/1**

```{r, echo=FALSE, out.width='70%'}
knitr::include_graphics(here("images", "logistic_regression.jpg"))
```

$$ P(Y = 1) = \frac{\exp{(X)}}{1 + \exp{(X)}}$$


# Odds Ratio

$$
\begin{aligned}
 P(Y = 1) &= \frac{\exp{(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots)}}{1 + \exp{(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots)}} \\\\
 \ln(\frac{p}{1-p}) &= \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots
\end{aligned}
$$

Interpretation of $\beta_1$: When adjusting for $X_2$, $X_3$, etc., a one-unit increase in $X_1$ results in an increase of $\beta_1$ in $\ln\left(\frac{p}{1 - p}\right)$ (the log-odds of the outcome).

> $\frac{p}{1-p}$ increases by a factor of $\exp(\beta_1)$. In other words, the odds ratio = $\exp(\beta_1)$.

## Finding Odds Ratio in SPSS

Go to `Analyze → Regression → Binary Logistic...`
Move `status` to the **Dependent** box, `sex`, `age`, and `rx_new` into the **Covariates** box.
```{r, echo=FALSE, out.width='85%'}
knitr::include_graphics(here("images", "odds1.png"))
```

Click **Categorical...**  
Select `rx_new`, move to **Categorical Covariates**  
Set **Reference Category** to **Last** (e.g., `Obs`)  
```{r, echo=FALSE, out.width='85%'}
knitr::include_graphics(here("images", "odds2.png"))
```

**Exp(B)** gives odds ratios

```{r, echo=FALSE, out.width='85%'}
knitr::include_graphics(here("images", "odds3.png"))
```

# Cox proportional hazard
**Time & Event**


# Time to event data

```{r, echo=F, fig.align='center'}
include_graphics("https://miro.medium.com/max/1440/1*S3lbo8tbgtklE7V-m4EsvQ.jpeg")
```

Most data are **right-censored**: 
the individual either died on day XX or survived up to day XX.

## Representing Time-to-Event with One Variable

```{r, echo=F}
rmarkdown::paged_table(data.frame(time = colon$time, status = colon$status, surv = with(colon, Surv(time, status))))
```


## Kaplan-meier plot

In survival analysis, Table 1 typically presents baseline characteristics.

- It is usually accompanied by the **log-rank test p-value** to compare survival between groups.

Go to **Analyze → Survival → Kaplan-Meier…**  
Set `time` as **Time**, `status(1)` as **Status**, `rx_new` as **Factor**  
```{r, echo=FALSE, out.width='70%'}
knitr::include_graphics(here("images", "kapp1.png"))
```

Click **Options** → Check:

- Survival table(s) 
- Mean and median survival 
- Survival plot   

```{r, echo=FALSE, out.width='40%'}
knitr::include_graphics(here("images", "kapp2.png"))
```

Click **Compare Factor…** → Check:

- Log rank 
- Pooled over strata   

```{r, echo=FALSE, out.width='70%'}
knitr::include_graphics(here("images", "kapp3.png"))
```

Click **OK** to see:

- Kaplan–Meier plot with censored cases (+)
- Log-rank p-value comparing survival curves  

```{r, echo=FALSE, out.width='85%'}
knitr::include_graphics(here("images", "kapp4.png"))
```


# Calculation: 
**Sort by time in ascending order**


$$
\begin{aligned}
P(t) &= \frac{\text{Survived at } t}{\text{At risk at } t} \quad \text{(Interval survival)} \\\\
S(t) &= S(t-1) \times P(t)
\end{aligned}
$$
```{r, echo=FALSE, out.width='85%'}
knitr::include_graphics(here("images", "LOGRANK.png"))
```

# Logrank test

Compute the expected number of events for each interval, then combine them for a chi-squared test.

> Is it combining the results across intervals?

- Assumes **similar event patterns** across intervals (**proportional hazards assumption**).

# Cox model

**Hazard function: $h(t)$**

- Probability of surviving up to time $t$ and dying immediately after

Cox model: evaluates the **Hazard Ratio (HR)**


$$
\begin{aligned}
h(t) &= \exp({\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots}) \\\\
     &= h_0(t) \exp({\beta_1 X_1 + \beta_2 X_2 + \cdots})     
\end{aligned}
$$
When \$X\_1\$ increases by 1, \$h(t)\$ increases by a factor of \$\exp(\beta\_1)\$. In other words:

$$\text{HR} = \exp{(\beta_1)}$$

# Characteristics

**Like Kaplan-Meier, statistics are calculated by intervals.**

- Assumes similar patterns across intervals (proportional hazards assumption)

**Time-independent HR: time is captured only by $h_0(t)$.**

- Model is simple: HR remains constant over time

- Time-dependent Cox models are also possible

**$h_0(t)$ is not estimated, which simplifies computation**

- This is why Cox is called a semi-parametric method

- But it's a limitation when building prediction models — you need to estimate $h_0(t)$ separately

## Cox Regression in SPSS

- Go to **Analyze → Survival → Cox Regression**  
```{r, echo=FALSE, out.width='65%'}
knitr::include_graphics(here("images", "cox1.png"))
```

- Set **Time** = `time`, **Status** = `status`  
  Click **Define Event**, enter value = 1  
```{r, echo=FALSE, out.width='65%'}
knitr::include_graphics(here("images", "cox2.png"))
```

- Move `sex`, `age`, `rx_new` to **Covariates**

- Click **Categorical**, add `rx_new`, set **Reference Category** to **Last**, click **Change**
- `Exp(B)` = hazard ratio  
```{r, echo=FALSE, out.width='65%'}
knitr::include_graphics(here("images", "cox3.png"))
```


# Survival Analysis: Proportional Hazards Assumption

Assumes a consistent trend: **survival curves should not cross**
- No formal test for the assumption is strictly required — it can be checked visually.

```{r, echo=FALSE, out.width='80%'}
knitr::include_graphics(here("images", "surva.png"))
```


# Landmark-analysis

Analyze separately by dividing time into intervals.
<center>
<img src="https://blog.zarathu.com/posts/2020-10-29-survivalpractice/index_files/figure-html/unnamed-chunk-6-1.png" width=50%></a>
</center>


# Time-dependent cox

```{r, echo=F}
vet2 <- survSplit(Surv(time, status) ~ ., data = veteran, cut=c(90, 180), episode = "tgroup", id = "id")
rmarkdown::paged_table(vet2)

```

# Time-dependet cox

```{r, echo=F}
vfit2 <- coxph(Surv(tstart, time, status) ~ trt + prior + karno:strata(tgroup), data=vet2)
summary(vfit2)

```


# Time-dependent covariate

In survival analysis, **all covariates should be measured before the index date**
- e.g., F/U lab, medication

To handle time-dependent covariates, a Cox model that accounts for this is required


```{r, echo=F}
N=100 #number of patients
set.seed(123)
df.tf<-simple.surv.sim(#baseline time fixed
 n=N, foltime=500,
 dist.ev=c('llogistic'),
 anc.ev=c(0.68), beta0.ev=c(5.8),
 anc.cens=1.2,
 beta0.cens=7.4,
 z=list(c("unif", 0.8, 1.2)),
 beta=list(c(-0.4),c(0)),
 x=list(c("bern", 0.5),
 c("normal", 70, 13)))
for (v in 4:7){
  df.tf[[v]] <- round(df.tf[[v]])
}
names(df.tf)[c(1,4,6,7)]<-c("id", "time", "grp","age")
df.tf <- df.tf[, -3]
 nft<-sample(1:10,
 N,replace=T)#number of follow up time points
crp<-round(abs(rnorm(sum(nft)+N,
 mean=100,sd=40)),1)
time<-NA
id<-NA
i=0
for(n in nft){
i=i+1
time.n<-sample(1:500,n)
time.n<-c(0,sort(time.n))
time<-c(time,time.n)
id.n<-rep(i,n+1)
id<-c(id,id.n)
}
df.td <- cbind(data.frame(id,time)[-1,],crp)


df <- tmerge(df.tf, df.tf, id = id, status1 = event(time, status))
df2 <- tmerge(df, df.td, id = id, crp = tdc(time, crp))
rmarkdown::paged_table(df2)
```

# Executive Summary 

|                      | Dafault           | Repeated measure | Survey     |
|----------------------|-------------------|------------------|------------|
| **Continuous**           | linear regression | GEE              | Survey GLM |
| **Event**                  | GLM (logistic)    | GEE              | Survey GLM |
| **Time & Event**         | Cox               | marginal Cox     | Survey Cox |
| **0,1,2,3 (rare event)** | GLM (poisson)     | GEE              | Survey GLM |


# END

```{=html}
<style>
  body {
    font-size: 0.8em;
  }

  h1 { font-size: 1.5em; }
  h2 { font-size: 1.25em; }
  h3 { font-size: 1.1em; }

  pre, code {
    font-size: 0.75em;
  }

  table {
    font-size: 0.8em;
  }

  .reveal .slides section {
    font-size: 0.8em;
  }
</style>
```

